---
title: "[Statistics] 11장 베이즈 통계"
description: "빅데이터 시대, 올바른 인사이트를 위한 통계X101 데이터분석"
date: 2025-12-15
categories: [Development, Statistics]
tags: [Statistics]
math: true
mermaid: true
---

## 1. 문제 상황: p-value 0.058의 딜레마

A/B 테스트를 진행했다. 결과는 다음과 같다.
- **A안**: 1000명 중 76명 전환 (7.6%)
- **B안**: 1000명 중 100명 전환 (10.0%)

직관적으로는 B안이 훨씬 좋아 보인다. 하지만 빈도주의 통계(Z-test)를 돌려보니 결과가 애매하다.

- **p-value**: 0.0582

### **<mark>빈도주의의 한계</mark>**
유의수준($\alpha$)을 0.05로 잡았다면, $p > 0.05$이므로 **"귀무가설을 기각할 수 없다"**는 결론이 나온다.
즉, **"통계적으로 유의미한 차이가 있다고 말할 수 없다"**는 소극적인 결론에 갇히게 된다.

> 의사결정자는 답답하다. "그래서 B안이 좋다는 거야, 아니라는 거야? 버려? 말아?"

## 2. 해결책: 베이지안 분석 (Bayesian Analysis)

같은 데이터를 두고 베이지안 관점(MCMC 시뮬레이션)으로 접근해보았다.
베이지안의 핵심은 두 집단의 차이를 **'확률분포'** 그 자체로 본다는 점이다.

### **<mark>Delta($\delta$)의 위력</mark>**
우리는 `pm.Deterministic('delta', p_B - p_A)`를 통해 두 집단 간 전환율 차이($\delta$)의 분포를 직접 구했다.

```python
# PyMC 모델 정의
with pm.Model() as ab_test_model:
    # 1. 사전분포 정의: 전환율 p_A와 p_B에 대한 '사전 믿음'을 설정합니다.
    #    아무 정보가 없다고 가정하고, 모든 가능성을 동등하게 보는 Beta(1, 1) 분포를 사용합니다.

    # TODO-1: A안의 전환율(p_A)에 대한 사전분포를 'p_A'라는 이름으로, alpha=1, beta=1로 설정하세요.
    p_A = pm.Beta('p_A', alpha=1, beta=1)
    # TODO-2: B안의 전환율(p_B)에 대해서도 동일하게 설정하세요.
    p_B = pm.Beta('p_B', alpha=1, beta=1)

    # 2. 두 전환율의 차이 계산: 우리가 정말 궁금한 'B가 A보다 얼마나 더 나은가'를 나타내는 변수를 만듭니다.
    # TODO-3: pm.Deterministic을 사용해, 첫 번째 인자로는 변수 이름 'delta'를, 두 번째 인자로는 p_B와 p_A의 차이를 넣어 정의하세요.
    delta = pm.Deterministic('delta', p_B - p_A)

    # 3. 가능도 정의: 모델을 실제 데이터와 연결합니다. 'n번 시도 중 k번 성공' 데이터는 이항분포(Binomial)로 설명할 수 있습니다.

    # TODO-4: A안의 관측 데이터가 이항분포를 따른다고 설정합니다.
    # (n: 총 방문자 수, p: 성공 확률(사전분포에서 정의한 변수), observed: 실제 구매자 수)
    obs_A = pm.Binomial('obs_A', n=nobs[0], p=p_A, observed=conversions[0])

    # TODO-5: B안에 대해서도 동일하게, 알맞은 변수들(nobs, p_B, conversions)을 인자에 연결하여 설정하세요.
    obs_B = pm.Binomial('obs_B', n=nobs[1], p=p_B, observed=conversions[1])

    # 4. MCMC 시뮬레이션 실행: 위에서 설계한 모델로부터 사후분포의 샘플들을 추출합니다.
    #    이 부분은 복잡한 계산을 PyMC가 대신 해주는 과정입니다.
    trace = pm.sample(4000, tune=1000, cores=1)

print("MCMC 시뮬레이션 완료!")

# 진단을 위해 trace 객체의 변수들을 출력합니다.
print("\nTrace 객체의 posterior 변수들:")
print(trace.posterior)


```

결과는 놀라웠다.
- **B안이 A안보다 좋을 확률**: **96.74%**
- **전환율 차이의 95% 구간(HDI)**: [0.001, 0.049] (0보다 큼)

### **<mark>해석의 전환</mark>**
빈도주의가 "차이가 0인지 아닌지"에 집착할 때, 베이지안은 다음과 같이 구체적인 답을 준다.

1.  **확신(Certainty)**: B안이 A안보다 나을 확률이 약 97%이다.
2.  **크기(Magnitude)**: 그 차이는 약 0.1%p에서 4.9%p 사이일 가능성이 가장 높다.

이 결과를 바탕으로 나는 **"3%의 리스크를 감수하고 97%의 승률을 가진 B안을 도입한다"**는 합리적인 비즈니스 의사결정을 내릴 수 있었다.

## 3. 베이지안의 주의점: 사전분포(Prior)

하지만 베이지안이 만능은 아니다. **"데이터가 적을 때"**가 문제다.

### **<mark>주사위 3번의 함정</mark>**
주사위를 3번 던져서 3이 3번 나왔다고 가정해보자. (데이터: 3, 3, 3)
- 만약 **무정보적 사전분포(아무것도 모름)**를 쓴다면?
    - 베이지안 모델은 "이 주사위는 100% 확률로 3만 나온다"라고 과신(Overfitting)할 수 있다.
- 만약 **정보적 사전분포(주사위는 원래 공평해)**를 쓴다면?
    - "3번 연속 3은 우연일 거야"라며 상식적인 결론으로 보정해준다.

> - 베이지안 분석은 **사전분포(Prior)** 설정에 따라 결과가 왜곡될 수 있다(주관성의 개입).
> - 따라서 데이터가 적을 때는 사전분포 설정에 신중해야 하며, 
가장 좋은 해결책은 **압도적으로 많은 데이터(Big Data)**를 확보하여 사전분포의 영향력을 지워버리는 것이다.

## 4. 결론

| 구분 | 빈도주의 (Frequentist) | 베이지안 (Bayesian) |
| :--- | :--- | :--- |
| **질문** | "차이가 0인가? (Yes/No)" | "B가 A보다 얼마나, 어떤 확률로 더 좋은가?" |
| **결과물** | p-value, 점추정 | 사후확률분포 (Posterior) |
| **장점** | 계산이 빠르고 객관적임 | 직관적 해석, 구체적 의사결정 가능 |
| **단점** | 해석이 난해함, 이분법적 사고 | 계산 비용 큼, 사전분포의 주관성 |

애매한 상황에서 의사결정을 내려야 한다면, 베이지안 분석은 강력한 무기가 된다. 

단, 그 무기를 다루는 사람의 **'사전 믿음'**이 타당한지 항상 경계해야 한다.