---
title: "[Statistics] 8장 통계 모형화"
description: "빅데이터 시대, 올바른 인사이트를 위한 통계X101 데이터분석"
date: 2025-12-12
categories: [Development, Statistics]
tags: [Statistics]
math: true
mermaid: true
---

## 8.1 선형회귀 원리의 확장

그동안 양적 데이터에만 적용했던 선형회귀를 다양한 데이터에 적용하기 위해 원리를 확장해 본다.

확장의 방향성은 크게 3가지이다.

1. 설명변수의 개수를 증가시키거나 유형을 변경
2. 반응변수의 유형을 변경
3. 회귀모형의 형태를 변경

### **<mark>다중회귀(Multiple Regression)</mark>**

설명변수가 하나인 단순회귀를 넘어, 설명변수가 여러 개인 것을 다중회귀라고 한다.

**다중선형회귀모형** :
$$y = a+ b_1x_1 + b_2x_2 + ... + b_kx_k + \epsilon$$

간단한 예시로 **몸무게($y$)**를 예측하기 위해 **키($x_1$)**와 **허리둘레($x_2$)**라는 두 가지 변수를 사용하는 상황을 생각해 볼 수 있다. 변수가 2개 이상이 되면 회귀선은 선이 아닌 **회귀 평면(plane)** 또는 초평면의 형태로 나타난다.

![다중회귀 예시](/assets/img/multiple_regression_example.png)

이때 각 $x_i$축에 대한 기울기 $b_i$를 **<mark>편회귀계수</mark>**라고 한다.

**결과 해석**
- 결과표를 통해 편회귀계수와 그 유의성을 파악한다.
- 편회귀계수($b_i$)의 의미 : $x_i$ 이외의 다른 설명변수들을 고정한 채로, $x_i$가 1 증가할 때의 $y$ 증가량을 뜻한다.

단, 편회귀계수의 크기만으로는 변수 간의 중요도를 직접 비교할 수 없다. (단위가 다를 수 있기 때문).
따라서 각 설명변수를 표준화하여 회귀분석을 진행한 **표준화편회귀계수**를 사용해 비교한다.

⚠️ 상관계수가 1에 가까운 강한 상관이 있는 변수들이 있다면, 후술할 **다중공선성** 문제를 의심해야 한다.

### **<mark>범주형 변수를 설명변수로</mark>**

범주형 변수(성별, 혈액형 등)를 회귀분석의 설명변수로 이용하려면 어떻게 해야 할까?
범주에는 대소 관계가 없으므로, 0 또는 1과 같은 **<mark>가변수(dummy variable)</mark>**로 변환하여 사용한다.

- **범주가 2개인 경우** : 예) 남자=0, 여자=1로 할당하여 적용. 결과 해석 시 어느 쪽이 0이고 1인지 확인이 필수적이다.
- **범주가 3개 이상인 경우** : $x=0, 1, 2$ 처럼 숫자를 키우는 것이 아니라, **(범주 개수 - 1)** 개의 가변수를 준비한다.
    - 예) 혈액형(A, B, O, AB) -> A형 여부(0/1), B형 여부(0/1), O형 여부(0/1) 변수 생성.
    - 원-핫 인코딩(One-Hot Encoding)과 유사하며, 이는 다중공선성을 회피하기 위함이다.
    - 회귀계수는 기준이 되는 범주(모두 0인 경우) 대비 다른 범주들이 어느 정도 차이가 나는지를 나타낸다.

### **<mark>공분산분석(ANCOVA)</mark>**

우리는 앞서 분산분석이나 t검정을 통해 집단 간 평균값을 비교했다. (기억이 안 난다면 [여기](https://chankyu99.github.io/posts/stastics6/)를 참고)

회귀분석의 관점에서 분산분석의 해석 정밀도를 향상시키는 방법이 바로 **<mark>공분산분석(Analysis of Covariance)</mark>**이다.
일반적인 분산분석 데이터에 영향을 줄 수 있는 양적 변수(예: 나이, 초기값 등)가 있을 때 이를 **공변량(covariate)**으로 추가하여 분석한다. 즉, 공변량에 따른 반응변수의 차이를 보정(통제)한 후 순수한 집단 간 차이를 본다.

**사용 조건**
1. 집단 간 회귀의 기울기가 서로 다르지 않아야 한다. (평행성 가정)
2. 회귀계수가 0이 아니어야 한다.

### **<mark>고차원 데이터 문제</mark>**

- **차원의 저주** : 설명변수(차원)가 늘어날수록 파라미터 추정에 필요한 데이터 양이 기하급수적으로 폭발하여 증가하는 현상.

- **<mark>다중공선성(Multicollinearity)</mark>** : 다중회귀에서 설명변수들 사이에 강한 상관관계가 존재하는 경우를 말한다.
    - 이 경우 회귀계수의 추정 오차가 커져 추정값의 신뢰성이 급격히 떨어진다.

직관적으로, $x_1$과 $x_2$가 거의 똑같이 움직인다면(강한 상관), $y$의 변화가 $x_1$ 때문인지 $x_2$ 때문인지 모델이 헷갈려 하는 상황이라고 볼 수 있다.

![다중공선성 직관적 예시](/assets/img/multicollinearity_example.png)

**다중공선성 측정** : **분산팽창인수(VIF, Variance Inflation Factor)**를 계산한다.

$$VIF_i = \frac {1}{1-R^2_i}$$

- $VIF \ge 10$ 이면(상관계수 약 0.95 이상), 두 변수 사이의 상관이 매우 강해 다중공선성이 있다고 판단한다.
- **해결책** : 서로 상관이 강한 변수 중 하나를 제거하거나, PCA(주성분분석) 등을 통해 차원을 축소한다.

---

## 8.2 회귀모형의 형태 바꾸기

### **<mark>상호작용(Interaction)</mark>**

기존 선형회귀모형($y = a + \sum b_ix_i$)은 각 변수가 독립적으로 $y$에 영향을 준다고 가정한다.
하지만 변수 간에 시너지 효과가 있다면? 이를 **상호작용**이라 하며, 곱셈항($c x_i x_j$)을 도입하여 모델링한다.

**언제 사용하는가?**
1. 선행 연구에서 상호작용이 있다고 밝혀졌거나 기대될 때
2. 데이터 분석 결과 분명한 상호작용 패턴이 보일 때
3. 상호작용의 유무 자체에 관심이 있을 때

### **<mark>이원배치 분산분석</mark>**

6장에서 배운 분산분석이 집단 간 차이라는 1가지 요인만 고려했다면(**일원배치**), 다중회귀분석처럼 여러 요인을 동시에 고려하는 것을 **다원배치 분산분석**이라 한다. 요인이 2개라면 **이원배치 분산분석**이 된다.

예를 들어, 식물의 성장을 볼 때 **'비료의 종류'**와 **'햇빛의 양'** 두 가지 요인을 동시에 고려하는 경우다. 이때 두 요인이 서로 영향을 주는 상호작용이 있는지도 확인할 수 있다.

![이원배치 분산분석 예시](/assets/img/two_way_anova_example.png)

가설검정 결과 상호작용항($c$)이 유의미하지 않다면 상호작용이 없다고 보고, 각각의 **주효과(main effect)**만을 평가한다.

### **<mark>비선형회귀</mark>**

$x$에 관해서는 $x^2, \log x$ 등을 사용하여 비선형적인 관계를 다루더라도, 파라미터($a, b$ 등)에 관해서 1차식이라면 여전히 **선형모형**의 범주에 들어간다.

하지만 파라미터 자체가 비선형적으로 결합된 경우를 **비선형회귀**라고 한다.
- $x$에 관한 비선형 모형화는 복잡하고 적절성 판단이 어렵다.
- 따라서 현상에 대한 적절한 물리적/화학적 모형이 이미 명확할 때 주로 사용한다.

**예시** : 효소 반응 속도론의 **미하엘리스-멘텐 식**
$$y = \frac {V_{max} [x]} {K_m + x}$$
여기서 $V_{max}$와 $K_m$이 추정해야 할 파라미터이다.

---

## 8.3 일반화선형모형(GLM)의 개념

### **<mark>선형회귀 원리의 확장</mark>**

지금까지 다룬 것을 "일반선형모형"이라 한다면, 이를 확장하여 **<mark>일반화선형모형(GLM, Generalized Linear Model)</mark>**이 등장한다.

- **기존** : 최소제곱법(거리 기반)
- **GLM** : 확률분포에 기반한 **최대가능도 방법(Maximum Likelihood Method)**으로 추정

정규분포 가정에 얽매이지 않고, 데이터의 성질(이항분포, 푸아송분포 등)을 고려하여 유연하게 모형화하는 방법이다. 이를 **통계 모형화**라고 한다.

**선형회귀가 적절하지 않은 상황?**
1. 반응변수가 **범주 2개(성공/실패)**로 나뉠 때
2. 반응변수가 **음이 아닌 정수(개수 데이터)**일 때
-> 이런 경우 직선으로 예측하면 범위가 맞지 않거나 의미가 모호해지므로 GLM을 사용한다.

### **<mark>가능도와 최대가능도 방법</mark>**

확률분포에서 데이터 $x$가 특정 파라미터 $\theta$를 가진 분포에서 나타날 확률을 다음과 같이 나타낸다.

$$P(x|\theta) = P(x_1 | \theta) \times P(x_2 | \theta) \times ... \times P(x_n | \theta)$$

이것을 **가능도(Likelihood) 함수**라고 한다.
가능도가 크다는 것은 해당 $\theta$ 분포에서 지금의 데이터가 관측될 확률이 높다는 뜻이다.

따라서 이 가능도 $L(\theta|x)$를 최대화하는 $\theta$를 찾아 추정값으로 삼는 것을 **<mark>최대가능도 방법(Maximum Likelihood Method)</mark>**이라고 한다.

### **<mark>로지스틱 회귀(Logistic Regression)</mark>**

반응변수가 **2개의 범주(0 또는 1)**로 나뉘는 경우 사용한다.
범주 하나가 일어날 확률을 $p$, 일어나지 않을 확률을 $1-p$라고 할 때, 설명변수 $x$에 따라 $p$가 어떻게 변하는지 조사한다.

데이터 $y_i$가 **이항분포** $B(N, p_i)$를 따른다고 간주하고 모델링한다. (이항분포에 대한 내용은 [여기](https://chankyu99.github.io/posts/stastics6/)를 참조)

$$p_i = \frac {1}{1 + \exp(-(a+bx_i))}$$

위 식의 우변이 **로지스틱 함수(Sigmoid)**이다. 선형함수 $ax+b$의 값($-\infty \sim \infty$)을 확률의 범위인 **0 ~ 1** 사이로 변환해 준다.

식을 변형하면 선형 결합 형태인 **로짓(logit) 함수**를 얻을 수 있다. GLM에서는 이를 **연결함수**라고 부른다.

$$\log \left( \frac {p}{1-p} \right) = a + bx$$

- **오즈(Odds)** : 사건이 일어날 확률과 일어나지 않을 확률의 비율 ($\frac {p}{1-p}$)
- **<mark>오즈비(Odds Ratio, OR)</mark>** : 두 집단의 오즈 비율.
    $$\text{OR} = \frac {p/(1-p)}{q/(1-q)}$$
    - $OR > 1$ : $p > q$ (해당 사건 발생 확률이 높음)
    - ⚠️ 주의 : 오즈비가 2라고 해서 발생 확률($p$)이 2배라는 뜻은 아니다. (오즈가 2배인 것)

### **<mark>푸아송 회귀(Poisson Regression)</mark>**

반응변수가 **0 이상의 정수(개수, count data)**일 때 사용하는 모형이다. (예: 하루 동안 웹사이트 방문자 수, 특정 시간 동안 발생한 불량품 수)

반응변수가 **푸아송 분포**를 따른다고 가정한다.
푸아송 분포는 "평균 $\lambda$번 일어나는 희귀한 사건이 $k$번 일어날 확률"을 나타낸다.

$$p(x=k) = \frac {\lambda^k e^{-\lambda}}{k!}$$

회귀식은 다음과 같이 연결된다. (연결함수는 로그함수)

$$\lambda_i = \exp(a+bx_i)$$

![푸아송분포 예시](/assets/img/poisson_distribution_example.png)

### **<mark>다양한 일반화선형모형 정리</mark>**

<br>

$$ \text{GLM} : \underbrace{f(z)}_{\text{연결함수}} = \underbrace{a+bx}_{\text{선형예측변수}}$$

| 확률분포 | 반응변수 | 연결함수 | 특징 |
| :---: | :---: | :---: | :--- |
| **이항분포** | 0 이상 정수 | 로짓함수 | 0 또는 1, 상한이 있는 개수 데이터 |
| **푸아송분포** | 0 이상 정수 | 로그함수 | 상한이 없는 개수 데이터, **평균=분산** |
| **음이항분포** | 0 이상 정수 | 로그/역함수 | 상한이 없는 개수 데이터, **평균 < 분산** (과분산 대처) |
| **정규분포** | 실수 | 항등함수 | 범위 제한 없음, 분산 일정 (일반 선형회귀) |
| **감마분포** | 양의 실수 | 로그/역함수 | 분산이 평균에 따라 변화 |

- **과분산(Overdispersion)** : 데이터의 분산이 확률분포가 가정한 분산보다 큰 경우.
    - 예) 푸아송은 평균=분산이어야 하는데, 분산이 훨씬 큰 경우.
    - 이럴 때 억지로 푸아송 회귀를 쓰면 제1종 오류가 발생할 수 있다.
    - **대처법** : 음이항 회귀를 쓰거나, **GLMM**을 사용한다.

### **<mark>일반화선형혼합모형(GLMM)</mark>**

**GLMM(Generalized Linear Mixed Model)**은 기존 모형에 **임의효과(Random Effect, $r_i$)**를 추가한 것이다.
$$a + bx + r_i$$
- $a, b$ : 고정효과 (전체적인 경향)
- $r_i$ : 임의효과 (개체별 특성이나 집단별 차이)

이를 통해 데이터 구조에 맞춘 유연한 모형화가 가능하며, 특히 과분산 문제를 해결하는 데 유용하다. 더 나아가 파라미터 자체가 확률분포를 따르는 **계층 모형(Hierarchical Model)**으로 확장할 수 있으며, 이 경우 베이즈 추정을 이용한다.

---

## 8.4 통계 모형의 평가와 비교

만들어진 모형이 좋은지 나쁜지, 혹은 두 모형 중 무엇이 더 나은지 평가하는 방법들이다.

### **<mark>왈드 검정(Wald Test)</mark>**

최대가능도 방법으로 얻은 **추정값**을 **표준오차**로 나눈 값(왈드 통계량)을 이용한다. 이를 통해 신뢰구간이나 p값을 구하여 회귀계수의 유의성을 검정한다.

### **<mark>가능도비 검정(Likelihood Ratio Test)</mark>**

두 모형의 **가능도(Likelihood)** 비율을 비교하는 방법이다.
단, 비교할 두 모형은 **내포 관계**(하나가 다른 하나를 포함하는 형태, 예: $y=a$ vs $y=a+bx$)여야 한다.

$$\Delta D_{1,2} = -2 \times (\log L^*_1 - \log L^*_2)$$

- 이 값이 클수록 대립가설(복잡한 모형)의 가능도가 더 크다는 뜻이며, 모형의 개선 효과가 유의미하다는 것을 의미한다.
- 표본 크기가 작을 때 왈드 검정보다 신뢰도가 높다.

### **<mark>AIC (아카이케 정보기준)</mark>**

정보량에 근거하여, **"새로운 데이터를 얼마나 잘 예측할 것인가?"**를 기준으로 모형을 선택한다.

$$\text{AIC} = -2\log L^* + 2k$$
($L^*$: 최대가능도, $k$: 파라미터 수)

- **AIC가 작을수록 좋은 모형**이다.
- 가능도가 클수록($\log L^*$ 증가) 좋지만, 파라미터 수($k$)가 많으면 페널티를 부여한다. (과적합 방지)
- 내포 관계가 아닌 모형끼리도 비교 가능하다.

### **<mark>BIC (베이지안 정보기준)</mark>**

AIC와 비슷하지만, **모형의 복잡함(파라미터 수)에 더 큰 페널티**를 부여한다.

$$\text{BIC} = -2\log L^* + k\log n$$
($n$: 표본 크기)

- **BIC가 작을수록 좋은 모형**이다.
- 표본 크기($n$)가 클수록 파라미터 수($k$)에 대한 페널티가 강해진다.
- 비교적 간단한 현상에서 "진짜 모형(True Model)"을 찾고자 할 때 유리하다.

**💡 요약**
- **AIC** : 복잡한 현실에서 **예측**이 중요할 때 (후보 중 실제 모형이 없다고 가정)
- **BIC** : 간단한 현상에서 **올바른 설명**이 중요할 때 (후보 중 실제 모형이 있다고 가정)