---
title: "Pandas로 비정제 데이터 다루기 & 택시 주행 데이터 분석 프로젝트"
description: "Pandas 핵심 기능 정리와 NYC 택시 데이터 전처리 미니 프로젝트"
date: 2025-12-01 
categories: [Development, Python]
tags: [Pandas, Data Cleaning, EDA]
math: false
---

오늘은 데이터 분석의 필수 라이브러리인 **Pandas**의 핵심 기능들을 정리하고, 이를 활용해 실제 **뉴욕 택시 주행 데이터(`trip.csv`)**를 전처리 및 분석해보는 시간을 가졌다.

---

# 1. Pandas 핵심 기능 및 데이터 전처리 가이드

데이터 분석 업무의 80%는 전처리라고 해도 과언이 아니다. `titanic.csv` 데이터를 예시로 Pandas에서 자주 사용되는 메서드와 데이터 클리닝 기법을 정리해 보았다.

### 📌 가장 많이 쓰이는 Top 10 Methods
데이터의 특성을 파악하고 형태를 변환하는 데 필수적인 메서드들이다.

1.  **`.describe()`**: 데이터프레임의 기술 통계량(평균, 표준편차, 4분위수 등)을 한눈에 파악할 수 있다.
2.  **`.value_counts()`**: 범주형 데이터의 고유값 빈도를 확인하는 데 유용하다.
3.  **`.sort_values()`**: 특정 컬럼의 값을 기준으로 데이터를 정렬한다.
4.  **`.apply()`**: 행 또는 열 단위로 복잡한 함수를 적용할 때 사용한다. (lambda 식과 자주 쓰임)
5.  **`.replace()`**: 특정 값을 다른 값으로 일괄 변경한다.
6.  **`pd.to_numeric()`**: 문자열 등을 숫자형으로 변환한다.
7.  **`.get_dummies()`**: 범주형 데이터를 원-핫 인코딩(One-hot encoding) 변환한다.
8.  **`Aggregation`**: 데이터를 그룹화하여 요약 통계를 낸다. (groupby)
9.  **`.merge()`**: SQL의 JOIN처럼 두 개 이상의 데이터프레임을 병합한다.
10. **`.tail()` / `.head()`**: 데이터의 끝 또는 앞부분을 확인한다.

### 데이터 정제 (Data Cleaning)

**1. 불필요한 컬럼 삭제와 복사**
데이터를 삭제하거나 수정할 때는 원본 데이터 보존 여부를 늘 고민해야 한다.
* **얕은 복사(Shallow Copy):** 변수만 새로 할당. 원본을 공유하므로 수정 시 원본도 바뀜.
* **깊은 복사(Deep Copy):** `.copy()`를 사용. 메모리 공간이 분리되어 원본에 영향을 주지 않음.
* **삭제:** `.drop(columns=['...'], axis=1)`을 사용하며, `inplace=True` 옵션으로 원본을 바로 수정할지 결정한다.

**2. 결측치(Missing Values) 처리**
결측치는 `.isna()`로 확인하며, 처리 방식은 크게 세 가지로 나뉜다.
* **삭제:** `.dropna()` - 노이즈를 없앨 수 있지만 데이터 손실이 발생한다.
* **대체:** `.fillna()` - 평균(mean)이나 중간값(median)으로 채운다. 데이터가 부족할 때 유용하다.
* **컬럼 삭제:** 결측치 비율이 너무 높은 컬럼은 아예 제거하는 것이 나을 수 있다.

**3. 이상치(Outlier) 탐지**
* **.describe()**: min, max 값을 통해 터무니없는 수치가 있는지 1차 확인.
* **Seaborn 시각화**: `boxplot`이나 `scatterplot`을 그려보면 눈에 띄게 벗어난 값(Outlier)을 직관적으로 찾을 수 있다.
* **IQR 방식**: $IQR = Q3 - Q1$ 일 때, 통상적으로 $1.5 \times IQR$ 범위를 벗어나면 이상치로 간주한다.

**4. 텍스트 및 날짜 처리**
* **String Methods**: `.str.split()`, `.str.isdigit()` 등을 통해 텍스트 데이터를 분리하거나 필터링할 수 있다.
* **Datetime**: `pd.to_datetime()`으로 변환 후 `.dt.year`, `.dt.day` 등으로 날짜 요소를 추출하거나, 시간 연산(예: 구매 소요 시간)을 수행할 수 있다.

---

# 2. 미니 프로젝트: NYC 택시 데이터 분석

앞서 배운 내용을 바탕으로 `trip.csv` (뉴욕 택시 운행 데이터)를 분석해 보았다. 단순히 코드를 실행하는 것을 넘어, **"이 데이터가 왜 이상하지?", "어떻게 처리해야 합리적일까?"**를 고민하며 전처리를 진행했다.

### 1단계: 데이터 훑어보기 및 기초 전처리
데이터를 불러온 후 `.info()`와 `.describe()`로 전체적인 구조를 파악했다.
* **중복 제거**: `passenger_name`이 중복된 경우가 발견되어 `.drop_duplicates()`로 정리했다.
* **범주 통일**: 결제 방식(`payment_method`)에 'Debit Card', 'Credit Card', 'Cash'가 섞여 있었다. 카드 결제는 하나로 묶는 게 분석에 용이할 것 같아 `replace`를 통해 'Card'로 통일했다.
* **시간 계산**: 승차(`pickup`)와 하차(`dropoff`) 시간이 문자열(Object)이었다. 이를 `datetime`으로 변환한 뒤, 두 시간의 차이를 계산해 주행 시간(`travel_time`)이라는 파생 변수를 만들었다.

### 2단계: 이상치를 판단하는 기준과 방법

통계치를 확인해 보니 비상식적인 값들이 보였다. 이를 해결하기 위해 **가설을 세우고 시각화로 확인한 뒤 정제**하는 과정을 거쳤다.

그 과정에서 `fare_amount` 컬럼의 scatterplot이 정말 애매했다.

![scatterplot](/assets/img/scatterplot.png)
_어디까지를 이상치로 보아야 하는가?_

데이터 분석에서 가장 중요한 것은 올바른 판단 기준을 세우는 것이라고 생각한다. 때문에 가장 어렵기도 하다고 생각한다.

이상치의 기준을 판단하는 것에 고민을 하던 중, Gemini에게 물어보았고, 3가지 방법을 알 수 있었다.

1. **도메인 지식** : 이 데이터가 무엇을 의미하는가?
- 주어진 플롯은 `fare_amount`로 택시 운행 요금을 나타낸다. 때문에 이상치로 판단되는 값들도 충분히 나올 수 있는 결과지만 만약 `fare_amount`가 택시 운행 요금이 아닌 고객 수라면 이상치로 판단하는 것이 더 정확할 수 있다.

2. **통계적 기준** : IQR 방식을 이용해 판단하기
- boxplot에서 사용한 IQR 방식을 사용해 기준값을 정하고, 이상치를 판단한다.

3. **다른 컬럼과의 관계를 통해 판단하기** : 비정상적인 패턴 찾아내기
- 이동거리(`trip_distance`)가 0인데 요금이 높은 경우, 혹은 이동 거리에 비해 요금이 터무니 없이 높은 경우 등 다른 컬럼과의 상관관계를 분석해 이상치를 판단하는 것이다. 내가 생각했을 때는 지금처럼 애매한 분석이라면 가장 효과적인 방법이라고 생각한다.

이를 통해 `fare_amount`가 150 이상인 데이터들은 대부분 거리와 비례하지 않는 비정상적인 값으로 판단해 이상치로 간주하고 제거하였다.

### 3단계: 상관관계 분석 및 마무리
전처리가 끝난 데이터로 다시 시각화를 해보니, 주행 거리와 요금 사이에 뚜렷한 **양의 상관관계**가 보였다. 마지막으로 요금, 팁, 통행료를 합산하여 총 지불 금액(`total_amount`) 컬럼을 생성하며 분석 준비를 마쳤다.

--- 

# **[결론]**
데이터 분석에서 가장 중요한 것은 코드 한 줄을 더 치는 것보다, **"데이터의 맥락(Context)을 이해하고 비정상적인 패턴을 의심하는 태도"**임을 깨달았다.